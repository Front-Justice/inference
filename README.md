# PROJET FRONT JUSTICE

ChaÃ®ne de traitement des minutes dans le cadre du projet **Front Justice**.

## ğŸ”§ PrÃ©requis

**Important** : toutes les opÃ©rations doivent Ãªtre effectuÃ©es depuis lâ€™environnement virtuel.

```bash
source env/bin/activate
```

1. Installation de YALTAi :

```bash
pip install YALTAi
```

ğŸ“ Lien : [https://github.com/ponteineptique/yaltai](https://github.com/ponteineptique/yaltai)

---

## âœï¸ Reconnaissance automatique de lâ€™Ã©criture

Le traitement suit une chaÃ®ne bien dÃ©finie :
- DÃ©tection des zones et des lignes via YALTAi et Kraken
- Reconnaissance des caractÃ¨res avec un modÃ¨le entraÃ®nÃ© (Kraken)
- Correction manuelle via eScriptorium (noms propres, date, numÃ©ro de jugement, armÃ©e)
- Post-traitement et extraction du contenu avec Ollama

---

### ğŸ“ Analyse de la mise en page

1. Se placer dans `htr/dataset`
2. Placer les numÃ©risations dans le dossier `dataset`
3. Lancer la dÃ©tection dâ€™objets et de lignes :

```bash
yaltai kraken --device cuda:0 -a -I "*.tif" --suffix ".xml" segment --yolo models/weights.pt -i models/250p-escript.mlmodel
```

ğŸ“ RÃ©sultat : fichiers ALTO `.xml`, gÃ©nÃ©rÃ©s depuis des images `.tif` avec support GPU.

---

### ğŸ”¡ Reconnaissance des caractÃ¨res

Appliquer le modÃ¨le entraÃ®nÃ© `250p_best.mlmodel` :

```bash
kraken -d cuda:0 -a -I "*.xml" -o ".ocr.xml" -f xml ocr -m models/250p_best.mlmodel
```

ğŸ—‚ RÃ©sultats stockÃ©s dans des fichiers `*.ocr.xml`.

#### â• Traitement des signatures

Remplacer toute ligne marquÃ©e `LABEL="CustomLine:signature"` par un simple `+` :

```bash
cd htr/scripts
python3 signature.py
```

---

## ğŸ” VÃ©rifications manuelles essentielles

Sur la **premiÃ¨re page de chaque minute**, vÃ©rifier :
- Les noms propres
- La date
- Le numÃ©ro de jugement
- Le nom de lâ€™armÃ©e concernÃ©e

Ces Ã©lÃ©ments critiques ne doivent pas Ãªtre laissÃ©s Ã  la seule reconnaissance automatique.

ğŸ“¦ Pour faciliter lâ€™import dans eScriptorium :

```bash
zip ocr.zip *.ocr.xml
```

AprÃ¨s correction dans eScriptorium, exporter les transcriptions au format `ALTO` dans `dataset/export`.

---

## ğŸ§¹ Post-traitement & structuration

### ğŸ§­ Remise en ordre des lignes

Assurer lâ€™ordre logique des lignes en premiÃ¨re page :

```bash
python3 ordre.py
```

### ğŸ†” Nettoyage des ID et des rÃ©gions

- Renommage cohÃ©rent des ID pour rÃ©gions et lignes
- Suppression des zones/lignes vides

```bash
python3 net-reg-lig.py
```

### ğŸ“ Structuration finale et extraction de texte

Organise chaque minute dans un dossier dÃ©diÃ© et extrait le texte dans un fichier `min_*.txt` :

```bash
python3 tri+texte.py
```

Ces fichiers serviront Ã  lâ€™analyse NER.

---

## ğŸ¤– Correction via Ollama

Appliquer le modÃ¨le LLM Phi-4 pour corriger automatiquement les transcriptions HTR, y compris les toponymes :

```bash
python3 post-oll.py
```

---

## âœ… Prochaines Ã©tapes

1. AmÃ©lioration de la qualitÃ© de lâ€™HTR :
   - Monter Ã  **1 000** sur Roboflow
   - Monter Ã  **500** pour la segmentation (pour dÃ©tecter les marges)
   - EntraÃ®ner un modÃ¨le `Party` pour la reconnaissance, Ã  lâ€™aide du dataset (âš ï¸ nÃ©cessite un GPU puissant)

